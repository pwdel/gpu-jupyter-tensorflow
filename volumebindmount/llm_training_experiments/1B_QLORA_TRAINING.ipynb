{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e64793",
   "metadata": {},
   "source": [
    "### 1B Parameter QLORA TRAINING\n",
    "\n",
    "* This is an attempt to train a 1B Parameter LLM using QLORA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d00b38",
   "metadata": {},
   "source": [
    "#### Check CUDA Availability\n",
    "\n",
    "* We first need to check to ensure that CUDA is available.  We can start with the nvidia-smi shell tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e8b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 21 01:24:11 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.146.02             Driver Version: 535.146.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1070        Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| 27%   34C    P2              29W / 151W |     16MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26b2d8",
   "metadata": {},
   "source": [
    "### Set Working Directory\n",
    "\n",
    "* Since we are importing various toolsets and saving items in specific folders, let's set the working directory so we know where we are globally for the remainder of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcac4e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Working Directory:  /home/jovyan/work/llm_training_experiments\n",
      "New Working Directory:  /home/jovyan/work/llm_training_experiments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory first\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "print(\"Original Working Directory: \", current_directory)\n",
    "\n",
    "# Set the working directory to the notebook's location\n",
    "notebook_dir = '/home/jovyan/work/llm_training_experiments'\n",
    "os.chdir(notebook_dir)\n",
    "print(\"New Working Directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109b8d6",
   "metadata": {},
   "source": [
    "### Check Torch and GPU Specifications\n",
    "\n",
    "* We need to ensure that torch is available within this kernel.\n",
    "* we have developed a utility to check the GPU availability which we can import with sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdc426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n",
      "GPU is available.\n",
      "Current GPU device: 0\n",
      "GPU Name: NVIDIA GeForce GTX 1070\n",
      "GPU Memory Capacity: 8.501919744 GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Since we set the working directory to the notebook directory, we append utils as being one direcotry back\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from specs import show_torch_and_gpu_stats\n",
    "\n",
    "show_torch_and_gpu_stats()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5600eda8",
   "metadata": {},
   "source": [
    "### Get Dataset for Training\n",
    "\n",
    "* We want to use a custom dataset, starting with our own CSV file, rather than using the dataset tools available on HuggingFace. We're doing it this way because we want to understand how to be able to fundamentally fine tune a language model according to our own custom datasets, not optimize against publicly available datasets.\n",
    "* That being said, we can use a sample dataset to start off with and transfer this into our own CSV file. The sample dataset we draw from is here: https://huggingface.co/datasets/Stevross/mmlu/viewer/abstract_algebra/dev\n",
    "\n",
    "#### What the MMLU Dataset Includes\n",
    "\n",
    "The MMLU dataset is a part of an LLM benchmark which is designed to measure LLM performance. The dataset includes various detailed questions, possible choices, and the correct answer. This format is typical for multiple-choice questions (MCQs), which are common in language understanding tasks. The components of MMLU include:\n",
    "\n",
    "* Question: The main body of the text presenting a scenario or asking a question.\n",
    "* Choices: A list of possible answers from which the correct one must be selected.\n",
    "* Answer: The correct choice, often indicated by an index or key that corresponds to the correct option in the choices list.\n",
    "\n",
    "The idea behind this format is that it is supposed to mimic real-world tasks, with the idea that in real-life, a person might take a test to get certified in something, and that test might be multiple-choice. Alternative open-ended essay based testing would be a different kind of benchmark that might include some kind of subjective assessment, as ELO Scores measure.\n",
    "\n",
    "#### What Our Dataset Needs to Include\n",
    "\n",
    "So to train a language model, you really want to bias it toward a set of answers to questions, so an input format like the following would suffice:\n",
    "\n",
    "```\n",
    "question\tanswer\n",
    "What is the definition of a group in abstract algebra?\tA set with an operation that is associative, has an identity element, and every element has an inverse.\n",
    "```![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8187394f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the definition of a group in abstract ...</td>\n",
       "      <td>A set with an operation that is associative, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How is a ring in algebra different from a group?</td>\n",
       "      <td>A ring has two operations (addition and multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a field in algebra?</td>\n",
       "      <td>A field is a ring in which every non-zero elem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain the concept of a vector space.</td>\n",
       "      <td>A vector space is a collection of vectors that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is an isomorphism in algebra?</td>\n",
       "      <td>An isomorphism is a bijective homomorphism bet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the definition of a group in abstract ...   \n",
       "1   How is a ring in algebra different from a group?   \n",
       "2                        What is a field in algebra?   \n",
       "3             Explain the concept of a vector space.   \n",
       "4                 What is an isomorphism in algebra?   \n",
       "\n",
       "                                              answer  \n",
       "0  A set with an operation that is associative, h...  \n",
       "1  A ring has two operations (addition and multip...  \n",
       "2  A field is a ring in which every non-zero elem...  \n",
       "3  A vector space is a collection of vectors that...  \n",
       "4  An isomorphism is a bijective homomorphism bet...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\"./abstract_algebra.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568b157",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    "\n",
    "* Once the data has been obtained, we can split it up into training and testing data using a standard sklearn tool, [model_selection](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), which splits data into random subsets for training and testing.\n",
    "* When this notebook was authored, sklearn was not installed so we need to use conda to get it installed and usable within the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f11adb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): | ^C\n",
      "/ "
     ]
    }
   ],
   "source": [
    "!conda install -y scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a37c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9f14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f165d2",
   "metadata": {},
   "source": [
    "* Once we have split the data up randomly, we can view the \"train\" and \"test\" set individually to make sure they look correct.\n",
    "* This train and test split is likely to be ineffective because they have nothing to do with one another, this is merely a development test, but we're doing it as a best practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe85988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the definition of a group in abstract ...</td>\n",
       "      <td>A set with an operation that is associative, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is an isomorphism in algebra?</td>\n",
       "      <td>An isomorphism is a bijective homomorphism bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain the concept of a vector space.</td>\n",
       "      <td>A vector space is a collection of vectors that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a field in algebra?</td>\n",
       "      <td>A field is a ring in which every non-zero elem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the definition of a group in abstract ...   \n",
       "4                 What is an isomorphism in algebra?   \n",
       "3             Explain the concept of a vector space.   \n",
       "2                        What is a field in algebra?   \n",
       "\n",
       "                                              answer  \n",
       "0  A set with an operation that is associative, h...  \n",
       "4  An isomorphism is a bijective homomorphism bet...  \n",
       "3  A vector space is a collection of vectors that...  \n",
       "2  A field is a ring in which every non-zero elem...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f19755f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How is a ring in algebra different from a group?</td>\n",
       "      <td>A ring has two operations (addition and multip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question  \\\n",
       "1  How is a ring in algebra different from a group?   \n",
       "\n",
       "                                              answer  \n",
       "1  A ring has two operations (addition and multip...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0506e27",
   "metadata": {},
   "source": [
    "### Config Model\n",
    "\n",
    "Prior to setting up a training run, you set up a configuration dictionary, CONFIG which organizes various settings and parameters for training a machine learning model. This configuration is structured into different sections.\n",
    "\n",
    "#### Directory and Naming Conventions\n",
    "\n",
    "* We need a START_MODEL_NAME which represents the model we are deriving from, on the HuggingFace hub.\n",
    "* We need a NEW_MODEL_NAME which represents what our model will be called afterward.\n",
    "* DATASET_PATH is where we can find our dataset that we're using to fine-tune the model.\n",
    "* OUTPUT_DIR is where we will save the various important files after the training is completed.\n",
    "\n",
    "#### Block, Batch, Steps, Save Limit, Learning Rate - Within basic_config\n",
    "\n",
    "* \"block_size\": is a part of the [Preprocess](https://huggingface.co/docs/transformers/tasks/language_modeling#preprocess) step, data often needs to be broken into smaller, manageable sequences. This is because models have a maximum sequence length they can handle (often 512 or 1024 tokens for Transformer-based models). The block_size parameter specifies the maximum length of these sequences. An example block_size of 128 means that each sequence of tokens fed to the model will be at most 128 tokens long. For a weaker GPU, the block size might need to be smaller.\n",
    "* \"num_train_epochs\": is a part of the [Trainer](https://huggingface.co/transformers/v4.2.2/main_classes/trainer.html) class, and represents the Total number of training epochs to perform (if not an integer, will perform the decimal part percents of the last epoch before stopping training). More epochs will take more time.\n",
    "* \"per_device_train_batch_size\": is an option found under [Gradient Accumulation](https://huggingface.co/docs/transformers/perf_train_gpu_one#gradient-accumulation), which is a method used to make training more efficient on a single GPU. Batch size during training determines how many samples are processed before the model's internal parameters are updated. A larger batch size typically leads to more stable and accurate gradient estimates, but it also requires more GPU memory. For example if per_device_train_batch_size is set to 4, it means each GPU (if you have more than one) processes 4 samples per iteration. Larger batch sizes on limited hardware, it can slow down the training process\n",
    "* \"save_steps\": Number of updates steps before two checkpoint saves, defaults to 500. This specifies the number of update steps (where the model's weights are updated) between saving the model checkpoints. A checkpoint is essentially a snapshot of your model's state, including its weights, optimizer state, and other parameters. For example if this is set to 500, it means the training process will save the model checkpoint after every 500 update steps. The tradeoff here is speed and space. Frequent saving takes up more space and can slow down the process due to I/O.  An example scenario would be, if you set per_device_train_batch_size=1 and gradient_accumulation_steps=4, the effective batch size becomes 4. Suppose your training dataset has 1000 examples. With an effective batch size of 4, there will be 250 update steps in one epoch (assuming no gradient accumulation). If save_steps is 500, the model will save a checkpoint after completing two epochs.\n",
    "* \"save_total_limit\": sets the maximum number of model checkpoints to keep, with older checkpoints being deleted.\n",
    "* \"learning_rate\":  key hyperparameter in the optimization process of training a machine learning model. It determines the size of the steps taken during the optimization process and thus the rate at which the model learns. A higher learning rate allows the model to learn faster, with larger updates to weights during training. However, if the learning rate is too high, the model might overshoot optimal solutions or fail to converge.\n",
    "\n",
    "#### bnb_config\n",
    "\n",
    "These are settings for quantization and data type used in the [BitsAndBytes library](https://github.com/TimDettmers/bitsandbytes), which is a wrapper . \n",
    "\n",
    "* \"load_in_4bit\": specifies whether to load the model in 4-bit quantization mode or not.\n",
    "* \"load_4bit_use_double_quant\": specifies whether to use double quantization, meaning twice in succession, which can used in certain scenarios to maintain precision. \n",
    "* \"bnb_4bit_quant_type\": the type of quantization to be used, such as nf4, which is an option in BitsAndBytes.\n",
    "* \"bnb_4bit_compute_dtype\": defines the data type, e.g. torch.bfloat16 for half precision.\n",
    "\n",
    "#### lora_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36a2e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basic_config': {'pretrained_model': 'tiiuae/falcon-rw-1b',\n",
       "  'start_model_path': '/home/jovyan/work/models/tiiuae/falcon-rw-1b',\n",
       "  'new_model': 'tiiuae/falcon-rw-1b-slight-tweak',\n",
       "  'train_path': '/home/jovyan/work/llm_training_experiments/abstract_algebra.csv',\n",
       "  'output_dir': '/home/jovyan/work/llm_training_experiments/tiiuae/falcon-rw-1b-slight-tweak/',\n",
       "  'block_size': 512,\n",
       "  'num_train_epochs': 1,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'save_steps': 1000,\n",
       "  'save_total_limit': 2,\n",
       "  'learning_rate': 5e-05},\n",
       " 'lora_config': {'r': 16,\n",
       "  'lora_alpha': 32,\n",
       "  'target_modules': ['query_key_value'],\n",
       "  'lora_dropout': 0.05,\n",
       "  'bias': 'none',\n",
       "  'task_type': 'CAUSAL_LM'},\n",
       " 'bnb_config': {'load_in_4bit': True,\n",
       "  'load_4bit_use_double_quant': True,\n",
       "  'bnb_4bit_quant_type': 'nf4',\n",
       "  'bnb_4bit_compute_dtype': 'torch.bfloat16'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_MODEL_NAME = \"tiiuae/falcon-rw-1b\"\n",
    "START_MODEL_PATH = \"/home/jovyan/work/models/\" + f\"{START_MODEL_NAME}\"\n",
    "NEW_MODEL_NAME = \"tiiuae/falcon-rw-1b-slight-tweak\"\n",
    "notebook_dir = '/home/jovyan/work/llm_training_experiments/'\n",
    "csv_file = 'abstract_algebra.csv'\n",
    "DATASET_PATH = notebook_dir + csv_file\n",
    "OUTPUT_DIR = f'{notebook_dir}{NEW_MODEL_NAME}/'\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    'basic_config': \n",
    "    {\n",
    "        \"pretrained_model\": f'{START_MODEL_NAME}',\n",
    "        \"start_model_path\": f'{START_MODEL_PATH}',\n",
    "        \"new_model\": f'{NEW_MODEL_NAME}',\n",
    "        \"train_path\": f'{DATASET_PATH}',\n",
    "        \"output_dir\": f'{OUTPUT_DIR}',\n",
    "        \"block_size\": 512,\n",
    "        \"num_train_epochs\": 1,\n",
    "        \"per_device_train_batch_size\": 2,\n",
    "        \"save_steps\": 1000,\n",
    "        \"save_total_limit\": 2,\n",
    "        \"learning_rate\": 5e-05,\n",
    "    },\n",
    "    'lora_config': \n",
    "    {\n",
    "        \"r\": 16,\n",
    "        \"lora_alpha\": 32,\n",
    "        \"target_modules\": [\"query_key_value\"],\n",
    "        \"lora_dropout\": 0.05,\n",
    "        \"bias\": \"none\",\n",
    "        \"task_type\": \"CAUSAL_LM\"\n",
    "    },\n",
    "    'bnb_config': {\n",
    "        \"load_in_4bit\": True,\n",
    "        \"load_4bit_use_double_quant\": True,\n",
    "        \"bnb_4bit_quant_type\": \"nf4\",\n",
    "        \"bnb_4bit_compute_dtype\": \"torch.bfloat16\"\n",
    "    },\n",
    "}\n",
    "\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04f824",
   "metadata": {},
   "source": [
    "### config.json and Saving\n",
    "\n",
    "* Running the save_config() function imported from utilities saves the config.json \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115b14e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory:  /home/jovyan/work/llm_training_experiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# remember to append the working path relative to our working directory\n",
    "print(\"Working Directory: \", os.getcwd())\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from config import save_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7137b964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config directory is: /home/jovyan/work/llm_training_experiments/tiiuae/falcon-rw-1b-slight-tweak/config\n",
      "Config file written to /home/jovyan/work/llm_training_experiments/tiiuae/falcon-rw-1b-slight-tweak/config/config.json.\n"
     ]
    }
   ],
   "source": [
    "save_config(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c2d2e",
   "metadata": {},
   "source": [
    "### Load Quantization Configuration to 4 bit from Hugging Face\n",
    "\n",
    "* [Quantization](https://huggingface.co/docs/transformers/main_classes/quantization) reduces memory and computation caosts by representing weights and activations with lower-precision data types, such as 4-bit integers or 4-bit integers rather than floats.\n",
    "* The [BitsAndBytesConfg](https://huggingface.co/docs/transformers/main_classes/quantization#transformers.BitsAndBytesConfig) is a wrapper class with all of the possible attribute and features that you can play with in a model that has been loaded using bitsandbytes for quantization.\n",
    "* Currently as the time of writing this, there are three different types of quantization, LM.int8, FP4, NF4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8848811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory:  /home/jovyan/work/llm_training_experiments\n",
      "load_in_4bit: True\n",
      "load_in_4bit_use_double_quant: True\n",
      "bnb_4bit_quant_type: nf4\n",
      "bnb_4bit_compute_dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# remember to append the working path relative to our working directory\n",
    "print(\"Working Directory: \", os.getcwd())\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from config import get_bnb_config\n",
    "\n",
    "bnb_config = get_bnb_config(CONFIG)\n",
    "\n",
    "# Look at some of the objects\n",
    "print(\"load_in_4bit:\", bnb_config.load_in_4bit)\n",
    "print(\"load_in_4bit_use_double_quant:\", bnb_config.load_in_4bit_use_double_quant)\n",
    "print(\"bnb_4bit_quant_type:\", bnb_config.bnb_4bit_quant_type)\n",
    "print(\"bnb_4bit_compute_dtype:\", bnb_config.bnb_4bit_compute_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78fb1ca",
   "metadata": {},
   "source": [
    "### Load the Lora Configuration\n",
    "\n",
    "* peft focuses on fine-tuning large-scale PLMs in a computationally and storage-efficient manner. Instead of fine-tuning all the model's parameters, PEFT methods fine-tune only a small number of (extra) model parameters. This approach can significantly decrease computational and storage costs while achieving performance comparable to full fine-tuning.\n",
    "\n",
    "* Integration with Hugging Face Accelerate: The package is seamlessly integrated with Hugging Face Accelerate for handling large-scale models, leveraging technologies like DeepSpeed and Big Model Inference for efficient computing.\n",
    "\n",
    "Supported Methods:\n",
    "\n",
    "* LoRA (Low-Rank Adaptation): Adapts large language models by adding low-rank matrices to existing weights.\n",
    "* Prefix Tuning, P-Tuning, and Prompt Tuning: These are techniques that involve optimizing continuous prompts or prepending learned embeddings to model inputs to adapt models to new tasks.\n",
    "* AdaLoRA: Adaptive budget allocation for fine-tuning.\n",
    "* MultiTask Prompt Tuning: Uses prompts for multitask transfer learning.\n",
    "* LoHa, LoKr, LoftQ: Different parameter-efficient tuning methods focusing on aspects like low-rank Hadamard product, Kronecker Adapter, and quantization, respectively.\n",
    "* OFT (Orthogonal Finetuning): A method for controlling diffusion in text-to-image models.\n",
    "\n",
    "* LoraConfig in peft:\n",
    "* LoraConfig is a configuration class for setting up Low-Rank Adaptation (LoRA) within the peft package. It would include parameters like r (rank of the adaptation), lora_alpha (scaling factor), lora_dropout (dropout rate for regularization), and target_modules (which parts of the model to apply LoRA to). The purpose of this configuration is to efficiently adapt large pre-trained models by adding low-rank structures to the model's layers, allowing for efficient fine-tuning with a smaller number of additional parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ba826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(537): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.1\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/tf_gpu_env\n",
      "\n",
      "  added / updated specs:\n",
      "    - peft\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    accelerate-0.26.1          |     pyhd8ed1ab_0         178 KB  conda-forge\n",
      "    peft-0.7.1                 |     pyhd8ed1ab_0          90 KB  conda-forge\n",
      "    safetensors-0.3.3          |   py39h9fdd4d6_1         1.0 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  accelerate         conda-forge/noarch::accelerate-0.26.1-pyhd8ed1ab_0\n",
      "  peft               conda-forge/noarch::peft-0.7.1-pyhd8ed1ab_0\n",
      "  safetensors        conda-forge/linux-64::safetensors-0.3.3-py39h9fdd4d6_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "safetensors-0.3.3    | 1.0 MB    | ##################################### | 100% \n",
      "peft-0.7.1           | 90 KB     | ##################################### | 100% \n",
      "accelerate-0.26.1    | 178 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f44ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "def get_lora_config(config):\n",
    "    \"\"\"Gets the Lora Config for creating adapter weights for model.\"\"\"\n",
    "    lora_config = LoraConfig(\n",
    "        r = config['lora_config']['r'],\n",
    "        lora_alpha = config['lora_config']['lora_alpha'],\n",
    "        target_modules = config['lora_config']['target_modules'],\n",
    "        lora_dropout = config['lora_config']['lora_dropout'],\n",
    "        bias = config['lora_config']['bias'],\n",
    "        task_type = config['lora_config']['task_type']\n",
    "    )\n",
    "    return lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3730feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'query_key_value'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lora_config(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d8f2f",
   "metadata": {},
   "source": [
    "### Load the Model and Tokenizer\n",
    "\n",
    "* tokenizer\n",
    "* model\n",
    "\n",
    "Once we load the model to cuda, we should get an output showing the model having been loaded as:\n",
    "\n",
    "```\n",
    "FalconModel(\n",
    "  (word_embeddings): Embedding(50304, 2048)\n",
    "  (h): ModuleList(\n",
    "    (0-23): 24 x FalconDecoderLayer(\n",
    "      (self_attention): FalconAttention(\n",
    "        (query_key_value): FalconLinear(in_features=2048, out_features=6144, bias=True)\n",
    "        (dense): FalconLinear(in_features=2048, out_features=2048, bias=True)\n",
    "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "      (mlp): FalconMLP(\n",
    "        (dense_h_to_4h): FalconLinear(in_features=2048, out_features=8192, bias=True)\n",
    "        (act): GELU(approximate='none')\n",
    "        (dense_4h_to_h): FalconLinear(in_features=8192, out_features=2048, bias=True)\n",
    "      )\n",
    "      (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
    "      (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
    "    )\n",
    "  )\n",
    "  (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
    ")\n",
    "```\n",
    "\n",
    "word_embeddings: This is an embedding layer with a vocabulary size of 50,304 and an embedding dimension of 2,048. Embedding layers are typically used to convert token indices into dense vectors of fixed size.\n",
    "\n",
    "h: This is a ModuleList containing multiple layers, specifically 24 FalconDecoderLayer instances, indexed from 0 to 23. This suggests the model has 24 layers, which is common in large transformer models.\n",
    "\n",
    "Each FalconDecoderLayer includes:\n",
    "\n",
    "self_attention: This is the self-attention mechanism, a hallmark of transformer models, with specific components:\n",
    "query_key_value: A linear layer that projects input features (of size 2,048) into query, key, and value vectors (of total size 6,144). This is essential for the attention mechanism.\n",
    "dense: Another linear layer that projects the output of the attention mechanism back to the feature size (2,048).\n",
    "attention_dropout: A dropout layer to prevent overfitting, set to 0.0, indicating it's currently not active.\n",
    "mlp: A feed-forward neural network (MLP) within each transformer layer, consisting of:\n",
    "dense_h_to_4h: A linear layer that expands the feature dimension from 2,048 to 8,192.\n",
    "act: An activation function, here a GELU (Gaussian Error Linear Unit), used for introducing non-linearity.\n",
    "dense_4h_to_h: Another linear layer to project the features back from 8,192 to 2,048 dimensions.\n",
    "input_layernorm and post_attention_layernorm: Layer normalization components, used to stabilize the learning process. They are applied before and after the self-attention mechanism, respectively.\n",
    "ln_f: This is a final layer normalization applied to the output of the last layer in the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa14f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ee5124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.empty_cache() executed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tiiuae/falcon-rw-1b were not used when initializing FalconModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing FalconModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FalconModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FalconModel(\n",
       "  (word_embeddings): Embedding(50304, 2048)\n",
       "  (h): ModuleList(\n",
       "    (0-23): 24 x FalconDecoderLayer(\n",
       "      (self_attention): FalconAttention(\n",
       "        (query_key_value): FalconLinear(in_features=2048, out_features=6144, bias=True)\n",
       "        (dense): FalconLinear(in_features=2048, out_features=2048, bias=True)\n",
       "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp): FalconMLP(\n",
       "        (dense_h_to_4h): FalconLinear(in_features=2048, out_features=8192, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (dense_4h_to_h): FalconLinear(in_features=8192, out_features=2048, bias=True)\n",
       "      )\n",
       "      (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from clear_gpu import clear_gpu_memory\n",
    "\n",
    "# use our utility to clear the GPU memory first.\n",
    "clear_gpu_memory()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['basic_config']['pretrained_model'], trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(CONFIG['basic_config']['pretrained_model'], trust_remote_code=True)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a0e51c",
   "metadata": {},
   "source": [
    "# Deleting the Model\n",
    "\n",
    "* So really, we don't need th model, we only need the tokenizer, and we're going to load the qlora model.\n",
    "* Running nvidia-smi on terminal will show the following:\n",
    "\n",
    "```\n",
    "0   N/A  N/A     36447      C   /opt/conda/envs/tf_gpu_env/bin/python      5088MiB\n",
    "```\n",
    "\n",
    "One we do the following, we can run nvidia-smi again and the pid in question along with the memory it is taking up should be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbbe8c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "model.to('cpu')\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628a79b",
   "metadata": {},
   "source": [
    "### Load QLora Model\n",
    "\n",
    "* Now that we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f8ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tiiuae/falcon-rw-1b were not used when initializing FalconModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing FalconModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FalconModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "DEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=121, Highest Compute Capability: 6.1.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Required library version not found: libbitsandbytes_cuda121_nocublaslt.so. Maybe you need to compile it from source?\n",
      "CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...\n",
      "\n",
      "================================================ERROR=====================================\n",
      "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
      "1. You need to manually override the PyTorch CUDA version. Please see: \"https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "2. CUDA driver not installed\n",
      "3. CUDA not installed\n",
      "4. You have multiple conflicting CUDA libraries\n",
      "5. Required library not pre-compiled for this bitsandbytes release!\n",
      "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
      "CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.\n",
      "================================================================================\n",
      "\n",
      "CUDA SETUP: Something unexpected happened. Please compile from source:\n",
      "git clone https://github.com/TimDettmers/bitsandbytes.git\n",
      "cd bitsandbytes\n",
      "CUDA_VERSION=121_nomatmul\n",
      "python setup.py install\n",
      "CUDA SETUP: Setup Failed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n",
      "/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: /opt/conda/envs/tf_gpu_env did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!                     If you run into issues with 8-bit matmul, you can try 4-bit quantization: https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m lora_config \u001b[38;5;241m=\u001b[39m get_lora_config(CONFIG)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# finally, the quantized lora model using get_peft_model from the peft library\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m quantized_lora_model \u001b[38;5;241m=\u001b[39m \u001b[43mget_peft_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/peft/mapping.py:133\u001b[0m, in \u001b[0;36mget_peft_model\u001b[0;34m(model, peft_config, adapter_name, mixed)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    132\u001b[0m     peft_config \u001b[38;5;241m=\u001b[39m _prepare_prompt_learning_config(peft_config, model_config)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/peft/peft_model.py:1043\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, peft_config: PeftConfig, adapter_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_prepare_inputs_for_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/peft/peft_model.py:125\u001b[0m, in \u001b[0;36mPeftModel.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_peft_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m PEFT_TYPE_TO_MODEL_MAPPING[peft_config\u001b[38;5;241m.\u001b[39mpeft_type]\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_additional_trainable_modules(peft_config, adapter_name)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_gradient_checkpointing\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/peft/tuners/lora/model.py:111\u001b[0m, in \u001b[0;36mLoraModel.__init__\u001b[0;34m(self, model, config, adapter_name)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, config, adapter_name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/peft/tuners/tuners_utils.py:90\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config\u001b[38;5;241m.\u001b[39mupdate(peft_config)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapter \u001b[38;5;241m=\u001b[39m adapter_name\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minject_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Copy the peft_config in the injected model.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpeft_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/peft/tuners/tuners_utils.py:247\u001b[0m, in \u001b[0;36mBaseTuner.inject_adapter\u001b[0;34m(self, model, adapter_name)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parent, target, target_name \u001b[38;5;241m=\u001b[39m _get_submodules(model, key)\n\u001b[1;32m    242\u001b[0m     optional_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded_in_8bit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_8bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: key,\n\u001b[1;32m    246\u001b[0m     }\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_and_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptional_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_target_modules_in_base_model:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget modules \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeft_config\u001b[38;5;241m.\u001b[39mtarget_modules\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the base model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the target modules and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/peft/tuners/lora/model.py:168\u001b[0m, in \u001b[0;36mLoraModel._create_and_replace\u001b[0;34m(self, lora_config, adapter_name, target, target_name, parent, current_key, **optional_kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m linear_types \u001b[38;5;241m=\u001b[39m (Linear,)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bnb_available():\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbnb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear8bitLt\n\u001b[1;32m    170\u001b[0m     linear_types \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (Linear8bitLt,)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bnb_4bit_available():\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_bnb_4bit_available, is_bnb_available\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MatmulLtState,\n\u001b[1;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     matmul_4bit\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/research/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     switchback_bnb,\n\u001b[1;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[1;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/research/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/research/nn/modules.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, device, dtype, nn\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalOptimManager\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n\u001b[1;32m     11\u001b[0m T \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.nn.Module\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/optim/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n",
      "File \u001b[0;32m/opt/conda/envs/tf_gpu_env/lib/python3.9/site-packages/bitsandbytes/cextension.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m     CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mgenerate_instructions()\n\u001b[1;32m     19\u001b[0m     CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mprint_log_stack()\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m    python -m bitsandbytes\u001b[39m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[1;32m     28\u001b[0m lib\u001b[38;5;241m.\u001b[39mcadam32bit_grad_fp32 \u001b[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n\u001b[1;32m     29\u001b[0m lib\u001b[38;5;241m.\u001b[39mget_context\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mc_void_p\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Since we set the working directory to the notebook directory, we append utils as being one direcotry back\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "\n",
    "from config import get_bnb_config\n",
    "from config import get_lora_config\n",
    "\n",
    "bnb_config = get_bnb_config(CONFIG)\n",
    "\n",
    "\n",
    "# load the model with the bitsandbytes configuration\n",
    "# model = FalconForCausalLM.from_pretrained(start_model_path, device_map=\"auto\", trust_remote_code=True, quantization_config=bnb_config)\n",
    "model = AutoModel.from_pretrained(\n",
    "    CONFIG['basic_config']['pretrained_model'],\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "# prepare quantized model using kbit training\n",
    "quantized_model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# get the lora configuration\n",
    "lora_config = get_lora_config(CONFIG)\n",
    "\n",
    "# finally, the quantized lora model using get_peft_model from the peft library\n",
    "quantized_lora_model = get_peft_model(\n",
    "    quantized_model, \n",
    "    lora_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a0ecb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model.to('cpu')\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ea1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        elif model_type == 'QLora':\n",
    "            \n",
    "            bnb_config = self.get_bnb_config()\n",
    "            model = FalconForCausalLM.from_pretrained(start_model_path, device_map=\"auto\", trust_remote_code=True, quantization_config=bnb_config)\n",
    "            quantized_model = prepare_model_for_kbit_training(model)\n",
    "            lora_config = self.get_lora_config()\n",
    "            quantized_lora_model = get_peft_model(quantized_model, lora_config)\n",
    "            self.MODEL = quantized_lora_model\n",
    "            return quantized_lora_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "tf_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
